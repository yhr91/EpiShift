{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-supervised model pre-training\n",
    "\n",
    "- This notebook describes the self-supervised model pretraining procedure\n",
    "- The results from applying this method did not appear to improve model performance and were thus not included in the final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from random import sample\n",
    "from torch.nn.modules.linear import Linear\n",
    "import torchvision.models as models\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive PreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_feats, num_hiddens=8, p_drop=0.0,\n",
    "                kernel_size=1000, conv_stride=5, \n",
    "                pool_stride=5, dilation=2, embed_size=4311):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=1, stride=conv_stride, \n",
    "                      kernel_size=kernel_size, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels=1, out_channels=1, stride=conv_stride,\n",
    "                      kernel_size=kernel_size, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Conv1d(in_channels=1, out_channels=1, stride=conv_stride,\n",
    "                      kernel_size=kernel_size, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.MaxPool1d(kernel_size=kernel_size, stride=pool_stride, padding=0, \n",
    "                         dilation=1)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(embed_size, num_hiddens)\n",
    "        \n",
    "    def forward(self, data: Tensor):\n",
    "        \n",
    "        embed = self.encoder(data.unsqueeze(1))\n",
    "        #breakpoint()\n",
    "        x = self.fc1(embed)\n",
    "        return x\n",
    "\n",
    "class PretrainedNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Auxiliary network defined to output two values. \n",
    "    The first being the output of a pretrained encoder, \n",
    "    and the second is a placeholder for downstream tasks\n",
    "    that require a second output. \n",
    "    \"\"\"\n",
    "    def __init__(self, encoder):\n",
    "        super(PretrainedNet, self).__init__()\n",
    "        self.encoder = encoder\n",
    "      \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded, None\n",
    "\n",
    "class MoCo(nn.Module):\n",
    "    \"\"\"\n",
    "    Build a MoCo model with: a query encoder, a key encoder, and a queue\n",
    "    https://arxiv.org/abs/1911.05722\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder, num_feats=40000,  dim=16, r=512, m=0.999, T=0.2):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (default: 16)\n",
    "        r: queue size; number of negative samples/prototypes (default: 512)\n",
    "        m: momentum for updating key encoder (default: 0.999)\n",
    "        T: softmax temperature \n",
    "        \"\"\"\n",
    "        super(MoCo, self).__init__()\n",
    "\n",
    "        self.r = r\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "\n",
    "        # create the encoders\n",
    "        # num_classes is the output fc dimension\n",
    "        self.encoder_q = base_encoder(num_feats=num_feats, num_hiddens=dim) # main model\n",
    "        self.encoder_k = base_encoder(num_feats=num_feats, num_hiddens=dim)\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "\n",
    "        # create the queue\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, r))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        # gather keys before updating queue\n",
    "        # keys = concat_all_gather(keys)\n",
    "\n",
    "        batch_size = keys.shape[0]\n",
    "#         sample_key = keys[-1] # last element in key\n",
    "\n",
    "        ptr = int(self.queue_ptr)\n",
    "        # ensure that the number of elements in the queue are divisible by batch_size\n",
    "#         while self.r % batch_size != 0: \n",
    "#             print(batch_size)\n",
    "#             keys = torch.cat((keys, sample_key), axis=0)\n",
    "#             print(keys)\n",
    "        assert self.r % batch_size == 0  # for simplicity\n",
    "\n",
    "        # replace the keys at ptr (dequeue and enqueue)\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.r  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    def forward(self, im_q, im_k=None, is_eval=False, cluster_result=None, index=None):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            im_q: a batch of query cells\n",
    "            im_k: a batch of key cells\n",
    "            is_eval: return momentum embeddings (used for clustering)\n",
    "            cluster_result: cluster assignments, centroids, and density\n",
    "            index: indices for training samples\n",
    "        Output:\n",
    "            logits, targets, proto_logits, proto_targets\n",
    "        \"\"\"\n",
    "       \n",
    "        if is_eval:\n",
    "            k = self.encoder_k(im_q)  \n",
    "            k = k.squeeze()\n",
    "            k = nn.functional.normalize(k, dim=1)            \n",
    "            return k\n",
    "        \n",
    "        # compute key features\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            self._momentum_update_key_encoder()  # update the key encoder\n",
    "\n",
    "            # shuffle for making use of BN\n",
    "            # im_k, idx_unshuffle = self._batch_shuffle_ddp(im_k)\n",
    "\n",
    "            k = self.encoder_k(im_k)  # keys: NxC\n",
    "            k = k.squeeze()\n",
    "            # print(k.shape)\n",
    "            k = nn.functional.normalize(k, dim=1)\n",
    "\n",
    "            # undo shuffle\n",
    "            #k = self._batch_unshuffle_ddp(k, idx_unshuffle)\n",
    "\n",
    "        # compute query features\n",
    "        q = self.encoder_q(im_q)  # queries: NxC\n",
    "        q = q.squeeze()\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        \n",
    "        # compute logits\n",
    "        # Einstein sum is more intuitive\n",
    "        # positive logits: Nx1\n",
    "        \n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        # negative logits: Nxr\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "\n",
    "        # logits: Nx(1+r)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "\n",
    "        # apply temperature\n",
    "        logits /= self.T\n",
    "\n",
    "        # labels: positive key indicators\n",
    "        # Nx(1+r)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "\n",
    "        # dequeue and enqueue\n",
    "        self._dequeue_and_enqueue(k)\n",
    "        \n",
    "\n",
    "        return logits, labels, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_transform(dataset, x, batch=None, args_transformation=None): \n",
    "    # x shape: (batch_size, num_genes)\n",
    "    # convert to numpy array\n",
    "#     x = x.numpy()\n",
    "    x_aug = []\n",
    "    x = batch[0]\n",
    "    orig_labels = batch[1]\n",
    "    \n",
    "    for sample in zip(x, orig_labels):\n",
    "        x_aug.append(random_transform(dataset, sample, batch=batch, args_transformation=args_transformation))\n",
    "    x_aug = torch.stack(x_aug, dim=0)\n",
    "    return x_aug\n",
    "    \n",
    "def random_transform(dataset, sample, batch=None, args_transformation=None): \n",
    "    \"\"\"\n",
    "    Args: \n",
    "        * batch (optional), the entire batch, use to leverage cell type in pretraining stage\n",
    "    \"\"\"\n",
    "    # sample (1, num_genes)\n",
    "    tr = transformation(dataset, sample, batch=batch)\n",
    "    \n",
    "    # Mask\n",
    "    tr.random_mask(args_transformation['mask_percentage'], args_transformation['apply_mask_prob'])\n",
    "\n",
    "    tr.ToTensor()\n",
    "\n",
    "    return tr.cell_profile # gene expression\n",
    "\n",
    "def pretrain_clear(model, dataset, pretrain_loader, optimizer, device, nepochs, batch_size): \n",
    "    print('Pretraining with contrastive learning.')\n",
    "    \n",
    "    aug_prob = 0.50 # temp\n",
    "    # define transformation \n",
    "    args_transformation = {\n",
    "        # mask\n",
    "        'mask_percentage': 0.2,\n",
    "        'apply_mask_prob': aug_prob,\n",
    "        \n",
    "        # (Add) gaussian noise\n",
    "        'noise_percentage': 0.8,\n",
    "        'sigma': 0.2,\n",
    "        'apply_noise_prob': aug_prob,\n",
    "\n",
    "        # inner swap\n",
    "        'swap_percentage': 0.1,\n",
    "        'apply_swap_prob': aug_prob,\n",
    "        \n",
    "        # cross over with 1\n",
    "        'cross_percentage': 0,\n",
    "        'apply_cross_prob': aug_prob,\n",
    "        \n",
    "        # cross over with many\n",
    "        'change_percentage': 0.25,\n",
    "        'apply_mutation_prob': aug_prob\n",
    "    }\n",
    "    \n",
    "    for epoch in tqdm(range(nepochs)):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, batch in enumerate(pretrain_loader):\n",
    "            # for each batch\n",
    "            x,_ = batch\n",
    "            \n",
    "            curr_batch_size = x.shape[0]\n",
    "            if curr_batch_size != batch_size: \n",
    "                #breakpoint()\n",
    "                continue\n",
    "\n",
    "            # generate positive pairs manually\n",
    "            x0 = batch_transform(dataset, x, batch=batch, args_transformation=args_transformation) # (batch_size, num_genes)\n",
    "            x1 = batch_transform(dataset, x, batch=batch, args_transformation=args_transformation) # (batch_size, num_genes)\n",
    "\n",
    "            x0 = x0.to(device)\n",
    "            x1 = x1.to(device)\n",
    "\n",
    "            logits, labels, _, _ = model(im_q=x0, im_k=x1, cluster_result=None, index=None) # (N, (1 + K))\n",
    "\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            loss = criterion(logits, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # compute gradients and backprop\n",
    "            optimizer.zero_grad()              \n",
    "            loss.backward()                    \n",
    "            optimizer.step()\n",
    "        \n",
    "        print(\"Loss: \", running_loss)\n",
    "        \n",
    "    return model\n",
    "\n",
    "class transformation():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 dataset,\n",
    "                 sample, \n",
    "                 batch=None):\n",
    "        self.dataset = dataset\n",
    "        self.sample = sample # (1, 3); X, orig_label\n",
    "        \n",
    "        self.cell_profile = sample[0].numpy()\n",
    "        self.curr_label = sample[1]\n",
    "        \n",
    "        self.gene_num = self.dataset.shape[1] # num of genes\n",
    "        self.cell_num = len(self.dataset) # total num of cells\n",
    "        self.batch = batch # (batch_size, 3), X, orig_labels (raw)\n",
    "        \n",
    "        # todo: convert these to torch tensors\n",
    "        self.batch_x = batch[0]\n",
    "        self.orig_labels = batch[1]\n",
    "    \n",
    "    def build_mask(self, masked_percentage: float):\n",
    "        mask = np.concatenate([np.ones(int(self.gene_num * masked_percentage), dtype=bool), \n",
    "                               np.zeros(self.gene_num - int(self.gene_num * masked_percentage), dtype=bool)])\n",
    "        np.random.shuffle(mask)\n",
    "        return mask\n",
    "    \n",
    "\n",
    "    def RandomCrop(self,\n",
    "                   crop_percentage=0.8):\n",
    "        mask = self.build_mask(crop_percentage)\n",
    "        self.cell_profile = self.cell_profile[mask]\n",
    "        self.gene_num = len(self.cell_profile)\n",
    "        self.dataset = self.dataset[:,mask]\n",
    "\n",
    "    def random_mask(self, \n",
    "                    mask_percentage: float = 0.15, \n",
    "                    apply_mask_prob: float = 0.5):\n",
    "\n",
    "        s = np.random.uniform(0,1)\n",
    "        if s<apply_mask_prob:\n",
    "            # create the mask for mutation\n",
    "            mask = self.build_mask(mask_percentage)\n",
    "            \n",
    "            # do the mutation with prob\n",
    "            self.cell_profile[mask] = 0\n",
    "\n",
    "    def random_gaussian_noise(self, \n",
    "                              noise_percentage: float=0.2, \n",
    "                              sigma: float=0.5, \n",
    "                              apply_noise_prob: float=0.3):\n",
    "\n",
    "        s = np.random.uniform(0,1)\n",
    "        if s < apply_noise_prob:\n",
    "            # create the mask for mutation\n",
    "            mask = self.build_mask(noise_percentage)\n",
    "            \n",
    "            # create the noise\n",
    "            noise = np.random.normal(0, 0.5, int(self.gene_num*noise_percentage))\n",
    "            \n",
    "            # do the mutation (maybe not add, simply change the value?)\n",
    "            self.cell_profile[mask] += noise\n",
    "\n",
    "\n",
    "    def random_swap(self,\n",
    "                    swap_percentage: float=0.1,\n",
    "                    apply_swap_prob: float=0.5):\n",
    "\n",
    "        ##### for debug\n",
    "        #     from copy import deepcopy\n",
    "        #     before_swap = deepcopy(cell_profile)\n",
    "        s = np.random.uniform(0,1)\n",
    "        if s<apply_swap_prob:\n",
    "            # create the number of pairs for swapping \n",
    "            swap_instances = int(self.gene_num*swap_percentage/2)\n",
    "            swap_pair = np.random.randint(self.gene_num, size=(swap_instances,2))\n",
    "            \n",
    "            # do the inner crossover with p\n",
    "        \n",
    "            self.cell_profile[swap_pair[:,0]], self.cell_profile[swap_pair[:,1]] = \\\n",
    "                self.cell_profile[swap_pair[:,1]], self.cell_profile[swap_pair[:, 0]]\n",
    "\n",
    "\n",
    "\n",
    "    def instance_crossover(self,\n",
    "                           cross_percentage: float=0.25,\n",
    "                           apply_cross_prob: float=0.4):\n",
    "        \n",
    "        # it's better to choose a similar profile to crossover\n",
    "        \n",
    "        s = np.random.uniform(0,1)\n",
    "        if s < apply_cross_prob:\n",
    "            # choose one instance for crossover\n",
    "            cross_idx = np.random.randint(self.cell_num)\n",
    "            cross_instance = self.dataset[cross_idx]\n",
    "            \n",
    "            # build the mask\n",
    "            mask = self.build_mask(cross_percentage)\n",
    "            \n",
    "            # apply instance crossover with p\n",
    "            tmp = cross_instance[mask].copy()\n",
    "        \n",
    "            cross_instance[mask], self.cell_profile[mask]  = self.cell_profile[mask], tmp\n",
    "\n",
    "\n",
    "    def same_type_crossover(self,\n",
    "                           cross_percentage: float=0.25,\n",
    "                           apply_cross_prob: float=0.4):\n",
    "        s = np.random.uniform(0,1)\n",
    "        if s < apply_cross_prob:\n",
    "            # choose one instance for crossover\n",
    "            cross_idx = np.random.randint(self.cell_num)\n",
    "            \n",
    "            # todo: instead of choosing random cross_idx, select cell_idx from within batch, O(1)\n",
    "            sp_inds = torch.where(self.species != self.curr_species)[0]\n",
    "            lbl_inds = torch.where(self.orig_labels == self.curr_label)[0]\n",
    "            combined = torch.cat((sp_inds, lbl_inds))\n",
    "            cross_inds = combined.unique()\n",
    "            \n",
    "            n_cross_inds = len(cross_inds)\n",
    "            if n_cross_inds > 0: \n",
    "                cross_idx = cross_inds[np.random.randint(n_cross_inds)] # select random cross_idx\n",
    "            elif n_lbl_inds > 0: \n",
    "                cross_idx = lbl_inds[np.random.randint(len(lbl_inds))]\n",
    "            else: \n",
    "                return\n",
    "                  \n",
    "            cross_instance = self.batch_x[cross_idx] # get other cell to swap with\n",
    "            cross_instance = cross_instance.cpu().detach().numpy() # convert to numpy \n",
    "            \n",
    "            # build the mask\n",
    "            mask = self.build_mask(cross_percentage)\n",
    "            \n",
    "            # apply instance crossover with p\n",
    "            tmp = cross_instance[mask].copy()\n",
    "        \n",
    "            cross_instance[mask], self.cell_profile[mask]  = self.cell_profile[mask], tmp\n",
    "            \n",
    "    def tf_idf_based_replacement(self, \n",
    "                                 change_percentage: float=0.25,\n",
    "                                 apply_mutation_prob: float=0.2,\n",
    "                                 new=False):\n",
    "\n",
    "        s = np.random.uniform(0,1)\n",
    "\n",
    "        # the speed is too slow\n",
    "        if s<apply_mutation_prob:\n",
    "            if not new:\n",
    "                mask = self.build_mask(change_percentage)\n",
    "                chosen = self.dataset[:,mask]\n",
    "                mutations = np.apply_along_axis(random_substitution, axis=0, arr=chosen)\n",
    "                self.cell_profile[mask] = mutations[0]\n",
    "            else:\n",
    "                mask = self.build_mask(change_percentage)\n",
    "                cell_random = np.random.randint(self.cell_num, size=int(self.gene_num * change_percentage))\n",
    "                chosen = self.dataset[cell_random, mask]\n",
    "                self.cell_profile[mask] = chosen\n",
    "\n",
    "\n",
    "    def ToTensor(self):\n",
    "        self.cell_profile = torch.from_numpy(self.cell_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "class EpiMap_DNAse_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, fnames, chr_, num_feats=None):\n",
    "        'Initialization'\n",
    "        self.tracks = []\n",
    "        for f in fnames:\n",
    "            print(f)\n",
    "            full_dna = torch.hstack(torch.load(f))\n",
    "            self.tracks.append(full_dna)\n",
    "        self.tracks = torch.stack(self.tracks)\n",
    "        self.labels = fnames\n",
    "            \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        return self.tracks[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloader for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 2881021\n",
    "model_dim = 8\n",
    "batch_size = 10\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./torch_data/00030.data\n",
      "./torch_data/00092.data\n",
      "./torch_data/00344.data\n",
      "./torch_data/00439.data\n",
      "./torch_data/00516.data\n",
      "./torch_data/00472.data\n",
      "./torch_data/00242.data\n",
      "./torch_data/00326.data\n",
      "./torch_data/00209.data\n",
      "./torch_data/00028.data\n",
      "./torch_data/00384.data\n",
      "./torch_data/00063.data\n",
      "./torch_data/00052.data\n",
      "./torch_data/00136.data\n",
      "./torch_data/00545.data\n",
      "./torch_data/00483.data\n",
      "./torch_data/00238.data\n",
      "./torch_data/00188.data\n",
      "./torch_data/00733.data\n",
      "./torch_data/00476.data\n",
      "./torch_data/00523.data\n",
      "./torch_data/00150.data\n",
      "./torch_data/00371.data\n",
      "./torch_data/00702.data\n",
      "./torch_data/00179.data\n",
      "./torch_data/00056.data\n",
      "./torch_data/00541.data\n",
      "./torch_data/00760.data\n",
      "./torch_data/00277.data\n",
      "./torch_data/00190.data\n",
      "./torch_data/00369.data\n",
      "./torch_data/00246.data\n",
      "./torch_data/00322.data\n",
      "./torch_data/00067.data\n",
      "./torch_data/00697.data\n",
      "./torch_data/00201.data\n",
      "./torch_data/00020.data\n",
      "./torch_data/00144.data\n",
      "./torch_data/00462.data\n",
      "./torch_data/00230.data\n",
      "./torch_data/00354.data\n",
      "./torch_data/00394.data\n",
      "./torch_data/00038.data\n",
      "./torch_data/00745.data\n",
      "./torch_data/00493.data\n",
      "./torch_data/00307.data\n",
      "./torch_data/00126.data\n",
      "./torch_data/00549.data\n",
      "./torch_data/00502.data\n",
      "./torch_data/00171.data\n",
      "./torch_data/00015.data\n",
      "./torch_data/00234.data\n",
      "./torch_data/00350.data\n",
      "./torch_data/00024.data\n",
      "./torch_data/00140.data\n",
      "./torch_data/00180.data\n",
      "./torch_data/00122.data\n",
      "./torch_data/00169.data\n",
      "./torch_data/00551.data\n",
      "./torch_data/00390.data\n",
      "./torch_data/00113.data\n",
      "./torch_data/00404.data\n",
      "./torch_data/00741.data\n",
      "./torch_data/00379.data\n",
      "./torch_data/00200.data\n",
      "./torch_data/00145.data\n",
      "./torch_data/00452.data\n",
      "./torch_data/00174.data\n",
      "./torch_data/00428.data\n",
      "./torch_data/00507.data\n",
      "./torch_data/00231.data\n",
      "./torch_data/00395.data\n",
      "./torch_data/00218.data\n",
      "./torch_data/00262.data\n",
      "./torch_data/00492.data\n",
      "./torch_data/00554.data\n",
      "./torch_data/00127.data\n",
      "./torch_data/00170.data\n",
      "./torch_data/00503.data\n",
      "./torch_data/00548.data\n",
      "./torch_data/00235.data\n",
      "./torch_data/00758.data\n",
      "./torch_data/00087.data\n",
      "./torch_data/00025.data\n",
      "./torch_data/00141.data\n",
      "./torch_data/00389.data\n",
      "./torch_data/00181.data\n",
      "./torch_data/00349.data\n",
      "./torch_data/00496.data\n",
      "./torch_data/00550.data\n",
      "./torch_data/00168.data\n",
      "./torch_data/00047.data\n",
      "./torch_data/00123.data\n",
      "./torch_data/00405.data\n",
      "./torch_data/00112.data\n",
      "./torch_data/00076.data\n",
      "./torch_data/00159.data\n",
      "./torch_data/00378.data\n",
      "./torch_data/00221.data\n",
      "./torch_data/00345.data\n",
      "./torch_data/00517.data\n",
      "./torch_data/00473.data\n",
      "./torch_data/00243.data\n",
      "./torch_data/00062.data\n",
      "./torch_data/00029.data\n",
      "./torch_data/00544.data\n",
      "./torch_data/00018.data\n",
      "./torch_data/00272.data\n",
      "./torch_data/00239.data\n",
      "./torch_data/00195.data\n",
      "./torch_data/00482.data\n",
      "./torch_data/00732.data\n",
      "./torch_data/00189.data\n",
      "./torch_data/00160.data\n",
      "./torch_data/00004.data\n",
      "./torch_data/00558.data\n",
      "./torch_data/00477.data\n",
      "./torch_data/00035.data\n",
      "./torch_data/00522.data\n",
      "./torch_data/00748.data\n",
      "./torch_data/00703.data\n",
      "./torch_data/00097.data\n",
      "./torch_data/00057.data\n",
      "./torch_data/00133.data\n",
      "./torch_data/00178.data\n",
      "./torch_data/00276.data\n",
      "./torch_data/00368.data\n",
      "./torch_data/00102.data\n",
      "./torch_data/00066.data\n",
      "./torch_data/00023.data\n",
      "./torch_data/00068.data\n",
      "./torch_data/00233.data\n",
      "./torch_data/00278.data\n",
      "./torch_data/00505.data\n",
      "./torch_data/00059.data\n",
      "./torch_data/00335.data\n",
      "./torch_data/00125.data\n",
      "./torch_data/00556.data\n",
      "./torch_data/00304.data\n",
      "./torch_data/00260.data\n",
      "./torch_data/00237.data\n",
      "./torch_data/00353.data\n",
      "./torch_data/00720.data\n",
      "./torch_data/00501.data\n",
      "./torch_data/00016.data\n",
      "./torch_data/00139.data\n",
      "./torch_data/00454.data\n",
      "./torch_data/00143.data\n",
      "./torch_data/00206.data\n",
      "./torch_data/00329.data\n",
      "./torch_data/00045.data\n",
      "./torch_data/00121.data\n",
      "./torch_data/00519.data\n",
      "./torch_data/00552.data\n",
      "./torch_data/00494.data\n",
      "./torch_data/00264.data\n",
      "./torch_data/00709.data\n",
      "./torch_data/00742.data\n",
      "./torch_data/00393.data\n",
      "./torch_data/00528.data\n",
      "./torch_data/00376.data\n",
      "./torch_data/00091.data\n",
      "./torch_data/00705.data\n",
      "./torch_data/00471.data\n",
      "./torch_data/00166.data\n",
      "./torch_data/00223.data\n",
      "./torch_data/00347.data\n",
      "./torch_data/00498.data\n",
      "./torch_data/00734.data\n",
      "./torch_data/00387.data\n",
      "./torch_data/00756.data\n",
      "./torch_data/00241.data\n",
      "./torch_data/00089.data\n",
      "./torch_data/00197.data\n",
      "./torch_data/00051.data\n",
      "./torch_data/00135.data\n",
      "./torch_data/00546.data\n",
      "./torch_data/00285.data\n",
      "./torch_data/00129.data\n",
      "./torch_data/00343.data\n",
      "./torch_data/00308.data\n",
      "./torch_data/00095.data\n",
      "./torch_data/00339.data\n",
      "./torch_data/00372.data\n",
      "./torch_data/00701.data\n",
      "./torch_data/00520.data\n",
      "./torch_data/00037.data\n",
      "./torch_data/00153.data\n",
      "./torch_data/00484.data\n",
      "./torch_data/00310.data\n",
      "./torch_data/00055.data\n",
      "./torch_data/00131.data\n",
      "./torch_data/00509.data\n",
      "./torch_data/00100.data\n",
      "./torch_data/00064.data\n",
      "./torch_data/00719.data\n",
      "./torch_data/00704.data\n",
      "./torch_data/00090.data\n",
      "./torch_data/00258.data\n",
      "./torch_data/00048.data\n",
      "./torch_data/00167.data\n",
      "./torch_data/00003.data\n",
      "./torch_data/00514.data\n",
      "./torch_data/00499.data\n",
      "./torch_data/00222.data\n",
      "./torch_data/00346.data\n",
      "./torch_data/00386.data\n",
      "./torch_data/00061.data\n",
      "./torch_data/00240.data\n",
      "./torch_data/00196.data\n",
      "./torch_data/00481.data\n",
      "./torch_data/00547.data\n",
      "./torch_data/00050.data\n",
      "./torch_data/00298.data\n",
      "./torch_data/00007.data\n",
      "./torch_data/00731.data\n",
      "./torch_data/00342.data\n",
      "./torch_data/00700.data\n",
      "./torch_data/00338.data\n",
      "./torch_data/00275.data\n",
      "./torch_data/00762.data\n",
      "./torch_data/00729.data\n",
      "./torch_data/00508.data\n",
      "./torch_data/00427.data\n",
      "./torch_data/00543.data\n",
      "./torch_data/00130.data\n",
      "./torch_data/00101.data\n",
      "./torch_data/00244.data\n",
      "./torch_data/00718.data\n",
      "./torch_data/00069.data\n",
      "./torch_data/00714.data\n",
      "./torch_data/00279.data\n",
      "./torch_data/00232.data\n",
      "./torch_data/00058.data\n",
      "./torch_data/00098.data\n",
      "./torch_data/00250.data\n",
      "./torch_data/00071.data\n",
      "./torch_data/00478.data\n",
      "./torch_data/00124.data\n",
      "./torch_data/00491.data\n",
      "./torch_data/00236.data\n",
      "./torch_data/00352.data\n",
      "./torch_data/00138.data\n",
      "./torch_data/00500.data\n",
      "./torch_data/00026.data\n",
      "./torch_data/00142.data\n",
      "./torch_data/00531.data\n",
      "./torch_data/00328.data\n",
      "./torch_data/00084.data\n",
      "./torch_data/00553.data\n",
      "./torch_data/00518.data\n",
      "./torch_data/00182.data\n",
      "./torch_data/00495.data\n",
      "./torch_data/00330.data\n",
      "./torch_data/00743.data\n",
      "./torch_data/00708.data\n",
      "./torch_data/00529.data\n",
      "./torch_data/00075.data\n"
     ]
    }
   ],
   "source": [
    "train_fnames = glob.glob('./torch_data/*.data')[:500]\n",
    "ds = EpiMap_DNAse_Dataset(train_fnames, \n",
    "                          chr_=np.arange(22), num_feats=x_dim)\n",
    "pretrain_loader = torch.utils.data.DataLoader(ds,\n",
    "                          batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run self-supervised model pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining with contrastive learning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1000 [00:00<?, ?it/s]/dfs/user/yhr/deepsnap/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "  0%|                                        | 1/1000 [00:23<6:30:34, 23.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  54.795970261096954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 2/1000 [00:46<6:24:43, 23.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  60.7951865196228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                        | 3/1000 [01:09<6:28:09, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  59.91996145248413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                       | 4/1000 [01:33<6:26:55, 23.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  59.772815227508545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                       | 5/1000 [01:56<6:24:39, 23.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  57.6645849943161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏                                       | 6/1000 [02:20<6:31:12, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  58.34118354320526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▎                                       | 7/1000 [02:43<6:25:42, 23.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  57.017547607421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▎                                       | 8/1000 [03:06<6:27:18, 23.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  54.07650089263916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▎                                       | 9/1000 [03:30<6:26:02, 23.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  54.42952787876129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                      | 10/1000 [03:51<6:16:41, 22.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  52.58727526664734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                      | 11/1000 [04:15<6:18:41, 22.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  52.3872195482254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                      | 12/1000 [04:39<6:23:08, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  51.53911292552948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                      | 13/1000 [05:01<6:19:10, 23.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  51.13242554664612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                      | 14/1000 [05:24<6:16:55, 22.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  51.62215864658356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▌                                      | 15/1000 [05:45<6:07:47, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  50.23833358287811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▌                                      | 16/1000 [06:08<6:08:18, 22.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  48.59812319278717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▋                                      | 17/1000 [06:30<6:06:06, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  47.76305329799652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▋                                      | 18/1000 [06:53<6:11:42, 22.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  49.835888385772705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▋                                      | 19/1000 [07:18<6:20:48, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  49.08571755886078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                      | 20/1000 [07:43<6:28:51, 23.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  47.021536350250244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                      | 21/1000 [08:06<6:26:44, 23.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  49.2674765586853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                      | 22/1000 [08:29<6:22:55, 23.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  45.306166887283325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▉                                      | 23/1000 [08:53<6:21:29, 23.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  46.04822647571564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▉                                      | 24/1000 [09:16<6:20:34, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  43.30674195289612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▉                                      | 25/1000 [09:39<6:19:57, 23.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  44.16975963115692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█                                      | 26/1000 [10:02<6:14:24, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  42.191275000572205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█                                      | 27/1000 [10:25<6:16:44, 23.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  41.75973558425903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█                                      | 28/1000 [10:48<6:12:03, 22.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  39.375956773757935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▏                                     | 29/1000 [11:12<6:16:40, 23.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  41.314897537231445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▏                                     | 30/1000 [11:34<6:10:26, 22.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  41.862290143966675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▏                                     | 31/1000 [11:57<6:11:12, 22.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  38.69015836715698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▏                                     | 32/1000 [12:20<6:10:23, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  38.92016792297363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▎                                     | 33/1000 [12:41<6:01:23, 22.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  38.35378098487854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█▎                                     | 34/1000 [13:04<6:03:24, 22.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  38.909512519836426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▎                                     | 35/1000 [13:29<6:14:08, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  36.544524788856506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▍                                     | 36/1000 [13:53<6:17:18, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  35.14623945951462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▍                                     | 37/1000 [14:16<6:15:30, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  37.36003839969635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▍                                     | 38/1000 [14:41<6:22:15, 23.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  36.58942353725433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▌                                     | 39/1000 [15:04<6:18:04, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  34.69355636835098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▌                                     | 40/1000 [15:28<6:18:25, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  35.845916628837585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▌                                     | 41/1000 [15:49<6:08:40, 23.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  36.197590351104736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▋                                     | 42/1000 [16:11<6:01:08, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  36.085304498672485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▋                                     | 43/1000 [16:33<6:01:00, 22.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  33.04039990901947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▋                                     | 44/1000 [16:56<5:58:30, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  33.84668129682541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|█▊                                     | 45/1000 [17:19<6:02:51, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  33.103936553001404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▊                                     | 46/1000 [17:43<6:04:59, 22.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  36.07655918598175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▊                                     | 47/1000 [18:06<6:07:33, 23.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  32.97489678859711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▊                                     | 48/1000 [18:30<6:10:25, 23.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  33.48684787750244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▉                                     | 49/1000 [18:55<6:16:15, 23.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  32.793139815330505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▉                                     | 50/1000 [19:18<6:12:25, 23.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  32.604711174964905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▉                                     | 51/1000 [19:40<6:05:27, 23.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  32.158603727817535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██                                     | 52/1000 [20:03<6:07:29, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  31.801232933998108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██                                     | 53/1000 [20:26<6:06:11, 23.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  31.12123614549637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██                                     | 54/1000 [20:50<6:07:22, 23.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  32.60605216026306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▏                                    | 55/1000 [21:13<6:05:43, 23.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  34.50523054599762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▏                                    | 56/1000 [21:36<6:02:47, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  30.065176486968994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▏                                    | 57/1000 [22:00<6:06:36, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  30.469613194465637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▎                                    | 58/1000 [22:22<6:03:58, 23.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  31.218258023262024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▎                                    | 59/1000 [22:45<5:59:34, 22.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  30.74374210834503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▎                                    | 60/1000 [23:09<6:03:55, 23.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  30.395654380321503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▍                                    | 61/1000 [23:32<6:02:56, 23.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  29.81772744655609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▍                                    | 62/1000 [23:56<6:05:35, 23.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  30.340017557144165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▍                                    | 63/1000 [24:19<6:06:56, 23.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  29.080747723579407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▍                                    | 64/1000 [24:42<6:03:44, 23.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  30.436717331409454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██▌                                    | 65/1000 [25:07<6:08:58, 23.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  30.57414698600769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▌                                    | 66/1000 [25:31<6:09:48, 23.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  27.902662992477417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▌                                    | 67/1000 [25:54<6:06:00, 23.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  29.11799454689026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▋                                    | 68/1000 [26:17<6:06:09, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  28.849283635616302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▋                                    | 69/1000 [26:39<5:57:26, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  29.69535118341446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▋                                    | 70/1000 [27:03<6:01:05, 23.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  28.813437163829803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▊                                    | 71/1000 [27:27<6:02:07, 23.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  28.159907042980194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▊                                    | 72/1000 [27:51<6:05:36, 23.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  29.6816828250885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▊                                    | 73/1000 [28:15<6:05:39, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  29.788634538650513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██▉                                    | 74/1000 [28:39<6:08:50, 23.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  28.24914199113846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██▉                                    | 75/1000 [29:01<5:59:42, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  27.842820286750793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██▉                                    | 76/1000 [29:26<6:05:07, 23.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  28.026356160640717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███                                    | 77/1000 [29:49<6:04:20, 23.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  26.178341031074524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███                                    | 78/1000 [30:12<5:57:14, 23.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  27.406740188598633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███                                    | 79/1000 [30:36<6:01:06, 23.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  26.915680646896362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███                                    | 80/1000 [30:59<6:00:42, 23.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  27.75031930208206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▏                                   | 81/1000 [31:22<5:57:44, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  28.783471286296844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▏                                   | 82/1000 [31:46<5:59:13, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  26.34739315509796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▏                                   | 83/1000 [32:10<5:59:36, 23.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  26.49003431200981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▎                                   | 84/1000 [32:32<5:55:19, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  25.4666810631752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███▎                                   | 85/1000 [32:56<5:55:09, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  26.18135753273964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▎                                   | 86/1000 [33:21<6:03:57, 23.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  26.15987539291382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▍                                   | 87/1000 [33:45<6:03:20, 23.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  26.56254553794861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▍                                   | 88/1000 [34:08<5:57:49, 23.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  26.957456409931183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▍                                   | 89/1000 [34:32<6:03:30, 23.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  25.14100855588913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▌                                   | 90/1000 [34:55<5:56:04, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  25.828516960144043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▌                                   | 91/1000 [35:19<6:00:39, 23.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  24.649092853069305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▌                                   | 92/1000 [35:43<5:57:33, 23.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  27.106676995754242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▋                                   | 93/1000 [36:04<5:49:16, 23.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.726694643497467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███▋                                   | 94/1000 [36:27<5:47:35, 23.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  24.157698690891266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▋                                   | 95/1000 [36:50<5:43:49, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  25.96976864337921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▋                                   | 96/1000 [37:11<5:37:26, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  25.7210231423378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▊                                   | 97/1000 [37:33<5:33:18, 22.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  24.4591326713562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▊                                   | 98/1000 [37:55<5:32:39, 22.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  25.614123463630676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▊                                   | 99/1000 [38:18<5:35:39, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.616032302379608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▊                                  | 100/1000 [38:43<5:46:55, 23.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  24.47020149230957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▊                                  | 101/1000 [39:06<5:46:52, 23.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.58426022529602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▉                                  | 102/1000 [39:30<5:51:06, 23.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.818148016929626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▉                                  | 103/1000 [39:53<5:50:13, 23.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  25.86614900827408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▉                                  | 104/1000 [40:16<5:45:06, 23.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  24.735981166362762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▉                                  | 105/1000 [40:39<5:43:52, 23.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.677704513072968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████                                  | 106/1000 [41:03<5:48:50, 23.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.18267387151718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████                                  | 107/1000 [41:26<5:47:09, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  24.82488650083542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████                                  | 108/1000 [41:50<5:49:06, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.97890317440033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▏                                 | 109/1000 [42:14<5:51:10, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  24.149271726608276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▏                                 | 110/1000 [42:36<5:46:19, 23.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.039542138576508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▏                                 | 111/1000 [43:00<5:48:26, 23.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.392949998378754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▎                                 | 112/1000 [43:22<5:39:45, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.504794538021088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▎                                 | 113/1000 [43:45<5:39:26, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.42701882123947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████▎                                 | 114/1000 [44:07<5:33:49, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.990214228630066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▎                                 | 115/1000 [44:30<5:36:29, 22.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.659405201673508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▍                                 | 116/1000 [44:53<5:38:18, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.78471213579178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▍                                 | 117/1000 [45:18<5:43:33, 23.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  25.413354814052582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▍                                 | 118/1000 [45:40<5:38:11, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.428977608680725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▌                                 | 119/1000 [46:03<5:37:27, 22.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.593595504760742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▌                                 | 120/1000 [46:27<5:42:52, 23.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.283519834280014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▌                                 | 121/1000 [46:51<5:46:26, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.38817650079727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▋                                 | 122/1000 [47:16<5:48:24, 23.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.723975956439972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▋                                 | 123/1000 [47:39<5:44:30, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.378616869449615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▋                                 | 124/1000 [48:02<5:41:50, 23.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.500273823738098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████▊                                 | 125/1000 [48:24<5:39:18, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  21.413520395755768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████▊                                 | 126/1000 [48:48<5:38:23, 23.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  21.267065465450287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████▊                                 | 127/1000 [49:10<5:32:22, 22.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.67323535680771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████▊                                 | 128/1000 [49:32<5:28:10, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  21.825888454914093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████▉                                 | 129/1000 [49:54<5:26:10, 22.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.461773544549942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████▉                                 | 130/1000 [50:15<5:21:21, 22.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  21.094304710626602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████▉                                 | 131/1000 [50:37<5:21:25, 22.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.623913198709488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████                                 | 132/1000 [50:59<5:19:27, 22.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.296002507209778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████                                 | 133/1000 [51:24<5:28:52, 22.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  21.455035269260406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████                                 | 134/1000 [51:46<5:26:30, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.57257318496704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▏                                | 135/1000 [52:09<5:27:33, 22.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.961760699748993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▏                                | 136/1000 [52:33<5:31:17, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  21.509026616811752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▏                                | 137/1000 [52:56<5:31:42, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  23.23324453830719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▏                                | 138/1000 [53:18<5:29:28, 22.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  21.335154235363007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▎                                | 139/1000 [53:42<5:32:25, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  22.22956931591034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▎                                | 140/1000 [54:06<5:33:40, 23.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.983900606632233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▎                                | 141/1000 [54:27<5:25:24, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.95748072862625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▍                                | 142/1000 [54:50<5:26:52, 22.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.21104794740677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▍                                | 143/1000 [55:13<5:27:13, 22.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.59234392642975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▍                                | 144/1000 [55:37<5:29:28, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  21.199881076812744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████▌                                | 145/1000 [55:59<5:24:38, 22.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.514151871204376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▌                                | 146/1000 [56:21<5:21:24, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.13683906197548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▌                                | 147/1000 [56:43<5:18:54, 22.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.005005359649658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▌                                | 148/1000 [57:07<5:23:40, 22.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.59991353750229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▋                                | 149/1000 [57:29<5:22:44, 22.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.480383276939392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▋                                | 150/1000 [57:53<5:25:08, 22.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.06749814748764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▋                                | 151/1000 [58:15<5:21:30, 22.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.38419944047928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▊                                | 152/1000 [58:38<5:23:24, 22.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.385937452316284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▊                                | 153/1000 [59:00<5:18:11, 22.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.644732296466827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████▊                                | 154/1000 [59:24<5:25:28, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.094037622213364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▉                                | 155/1000 [59:46<5:21:16, 22.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.091417759656906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▌                              | 156/1000 [1:00:09<5:21:06, 22.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.561686158180237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▋                              | 157/1000 [1:00:32<5:21:07, 22.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.08300393819809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▋                              | 158/1000 [1:00:58<5:30:50, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.25833386182785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▋                              | 159/1000 [1:01:20<5:24:45, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  21.283997923135757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▊                              | 160/1000 [1:01:43<5:25:23, 23.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.738776206970215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▊                              | 161/1000 [1:02:07<5:28:35, 23.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.780274033546448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▊                              | 162/1000 [1:02:29<5:22:53, 23.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.911427080631256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▊                              | 163/1000 [1:02:54<5:26:28, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  19.36824569106102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████▉                              | 164/1000 [1:03:16<5:22:53, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  20.407461136579514\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "# Self-supervised pre-training\n",
    "model = MoCo(ConvEncoder, num_feats=x_dim, dim=model_dim, r=batch_size).to(\n",
    "    device)\n",
    "optim_pretrain = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "pretrain_epochs = 1000\n",
    "model = pretrain_clear(model, ds.tracks, \n",
    "                       pretrain_loader, optim_pretrain,\n",
    "                       device, pretrain_epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and model embeddings embeddings\n",
    "pretrain_encoder = PretrainedNet(model.encoder_q)\n",
    "torch.save(pretrain_encoder.state_dict(), 'pretrain_encoder_1000epoch_500data_fulldna')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply pretrained model to Alzheimer's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If loading pre-trained state\n",
    "model = MoCo(ConvEncoder, num_feats=x_dim, dim=model_dim, r=batch_size).to(\n",
    "    device)\n",
    "\n",
    "pretrain_encoder = PretrainedNet(model.encoder_q)\n",
    "pretrain_encoder.load_state_dict(torch.load('pretrain_encoder_1000epoch_500data_fulldna_onlymask'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pretrain_encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpiShift(nn.Module):\n",
    "    \"\"\"\n",
    "    Training Alzheimer's prediction model, pre-trained on EpiMap data\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, conv_stride=2, kernel_size=500, dilation=2, \n",
    "                 embed_size=4302, pretrain_encoder=None):\n",
    "        super(EpiShift, self).__init__()\n",
    "        \n",
    "        self.encoder = pretrain_encoder.encoder.encoder\n",
    "        self.fc1 = nn.Linear(embed_size, 1)\n",
    "        \n",
    "    def forward(self, data: Tensor):\n",
    "        \n",
    "        encoded = self.encoder(data)\n",
    "        x = self.fc1(encoded)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up dataloaders\n",
    "\n",
    "class Rush_DNAse_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, fnames, label_file):\n",
    "        'Initialization'\n",
    "        \n",
    "        tracks = []\n",
    "        file_ids = []\n",
    "        \n",
    "        for f in fnames:\n",
    "            read_in = torch.load(f)\n",
    "            if len(read_in)==2875012:\n",
    "                tracks.append(read_in)\n",
    "                file_ids.append(f.split('/')[-1].split('.')[0])\n",
    "            \n",
    "        self.tracks = torch.stack(tracks)\n",
    "        self.labels = label_file.set_index('file_accession').loc[file_ids,'label'].values\n",
    "        self.labels = Tensor((self.labels=='AD').astype('float'))\n",
    "            \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        return self.tracks[index], self.labels[index]\n",
    "    \n",
    "def get_train_val_test(fold_num, labels):  \n",
    "    fold = pd.read_csv('torch_data/rush/new/DNase_fold_'+str(fold_num)+'_labels.csv', index_col=0)\n",
    "    \n",
    "    test_ids = fold.index.values\n",
    "    train_ids = list(set(labels['file_accession'].values).difference(set(test_ids)))\n",
    "    train_ids, val_ids = train_test_split(train_ids, test_size=0.1, \n",
    "                                  random_state=10)\n",
    "    \n",
    "    return train_ids, val_ids, test_ids\n",
    "\n",
    "def get_fnames(fnames, ids):\n",
    "    filename2id_map = {f.split('/')[-1].split('.')[0]:idx  \n",
    "                     for idx, f in enumerate(fnames)}\n",
    "    \n",
    "    filename_idx = []\n",
    "    for f in train_ids:\n",
    "        try:\n",
    "            filename_idx.append(filename2id_map[f])\n",
    "        except:\n",
    "            print('Not found: ',f)\n",
    "    return np.array(fnames)[filename_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epishift(train_dataloader, val_dataloader, num_epochs=100,\n",
    "                  lr=1e-3, pretrain_encoder=None):\n",
    "    ## Trainer\n",
    "    model = EpiShift(pretrain_encoder=pretrain_encoder)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, \n",
    "                           weight_decay=5e-4)\n",
    "    #scheduler = StepLR(optimizer, step_size=1, \n",
    "    #                   gamma=0.5)\n",
    "    min_val_loss = np.inf\n",
    "    m = nn.Sigmoid()\n",
    "    best_model = deepcopy(model)\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "\n",
    "        # Training epoch\n",
    "        for step, data in enumerate(train_dataloader):\n",
    "            X = data[0].to(device)\n",
    "            y = data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(X.unsqueeze(1))\n",
    "            loss = criterion(m(pred).squeeze(), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss)\n",
    "            #print(\"Training Loss:\", loss.detach().cpu().numpy())\n",
    "\n",
    "        # Validation step\n",
    "        val_loss_sum = 0\n",
    "        model.eval()\n",
    "        for step, data in enumerate(val_dataloader):\n",
    "            X = data[0].to(device)\n",
    "            y = data[1].to(device)\n",
    "\n",
    "            val_pred = model(X.unsqueeze(1))\n",
    "            val_loss = criterion(m(val_pred).squeeze(), y)\n",
    "            val_loss_sum += val_loss\n",
    "\n",
    "        print(\"Validation Loss:\", val_loss_sum.detach().cpu().numpy())\n",
    "        if val_loss_sum < min_val_loss:\n",
    "            min_val_loss = val_loss_sum\n",
    "            best_model = deepcopy(model)\n",
    "            \n",
    "    return best_model\n",
    "            \n",
    "\n",
    "def test_epishift(model, test_dataloader):\n",
    "    test_preds = []\n",
    "    ys = []\n",
    "    model.eval()\n",
    "    m = nn.Sigmoid()\n",
    "    model.to(device)\n",
    "    \n",
    "    for step, data in enumerate(test_dataloader):\n",
    "        X = data[0].to(device)\n",
    "        y = data[1].to(device)\n",
    "\n",
    "        test_pred = m(model(X.unsqueeze(1))).squeeze()\n",
    "        tp = test_pred.squeeze().cpu().detach().numpy()\n",
    "        test_preds.extend(tp)\n",
    "        ys.extend(y.cpu().detach().numpy())\n",
    "        \n",
    "    return {'pred':test_preds, \n",
    "            'truth':ys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('./experiment_labels.csv')\n",
    "rush_fnames = glob.glob('./torch_data/rush/new/*.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in model.parameters():\n",
    "#    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found:  ENCFF345KPY\n",
      "Not found:  ENCFF912LYR\n",
      "Not found:  ENCFF762VOE\n",
      "Not found:  ENCFF738TVC\n",
      "Not found:  ENCFF808SYD\n",
      "Not found:  ENCFF771XYK\n",
      "Not found:  ENCFF258ANV\n",
      "Not found:  ENCFF284VFV\n",
      "Not found:  ENCFF080KYI\n",
      "Not found:  ENCFF658HZK\n",
      "Not found:  ENCFF845ONN\n",
      "Not found:  ENCFF509MZI\n",
      "Not found:  ENCFF570NEW\n",
      "Not found:  ENCFF970MGQ\n",
      "Not found:  ENCFF788PUW\n",
      "Not found:  ENCFF957XRW\n",
      "Not found:  ENCFF248LJB\n",
      "Not found:  ENCFF107YAW\n",
      "Not found:  ENCFF707GIJ\n",
      "Not found:  ENCFF823FJI\n",
      "Not found:  ENCFF203FBD\n",
      "Not found:  ENCFF899VMA\n",
      "Not found:  ENCFF509ZIC\n",
      "Not found:  ENCFF009AKE\n",
      "Not found:  ENCFF354MPI\n",
      "Not found:  ENCFF586KEK\n",
      "Not found:  ENCFF166SFX\n",
      "Not found:  ENCFF367FEB\n",
      "Not found:  ENCFF042XFA\n",
      "Not found:  ENCFF457BBP\n",
      "Not found:  ENCFF311IDM\n",
      "Not found:  ENCFF180CEK\n",
      "Not found:  ENCFF822OZH\n",
      "Not found:  ENCFF258FWH\n",
      "Not found:  ENCFF015EMC\n",
      "Not found:  ENCFF197DZP\n",
      "Not found:  ENCFF693QKW\n",
      "Not found:  ENCFF342TEJ\n",
      "Not found:  ENCFF905NDM\n",
      "Not found:  ENCFF879JZU\n",
      "Not found:  ENCFF952AHW\n",
      "Not found:  ENCFF563JCI\n",
      "Not found:  ENCFF269MUV\n",
      "Not found:  ENCFF482LTF\n",
      "Not found:  ENCFF614VLQ\n",
      "Not found:  ENCFF624FHC\n",
      "Not found:  ENCFF479KNI\n",
      "Not found:  ENCFF589PEM\n",
      "Not found:  ENCFF041HBD\n",
      "Not found:  ENCFF124RDD\n",
      "Not found:  ENCFF725USM\n",
      "Not found:  ENCFF345KPY\n",
      "Not found:  ENCFF912LYR\n",
      "Not found:  ENCFF762VOE\n",
      "Not found:  ENCFF738TVC\n",
      "Not found:  ENCFF808SYD\n",
      "Not found:  ENCFF771XYK\n",
      "Not found:  ENCFF258ANV\n",
      "Not found:  ENCFF284VFV\n",
      "Not found:  ENCFF080KYI\n",
      "Not found:  ENCFF658HZK\n",
      "Not found:  ENCFF845ONN\n",
      "Not found:  ENCFF509MZI\n",
      "Not found:  ENCFF570NEW\n",
      "Not found:  ENCFF970MGQ\n",
      "Not found:  ENCFF788PUW\n",
      "Not found:  ENCFF957XRW\n",
      "Not found:  ENCFF248LJB\n",
      "Not found:  ENCFF107YAW\n",
      "Not found:  ENCFF707GIJ\n",
      "Not found:  ENCFF823FJI\n",
      "Not found:  ENCFF203FBD\n",
      "Not found:  ENCFF899VMA\n",
      "Not found:  ENCFF509ZIC\n",
      "Not found:  ENCFF009AKE\n",
      "Not found:  ENCFF354MPI\n",
      "Not found:  ENCFF586KEK\n",
      "Not found:  ENCFF166SFX\n",
      "Not found:  ENCFF367FEB\n",
      "Not found:  ENCFF042XFA\n",
      "Not found:  ENCFF457BBP\n",
      "Not found:  ENCFF311IDM\n",
      "Not found:  ENCFF180CEK\n",
      "Not found:  ENCFF822OZH\n",
      "Not found:  ENCFF258FWH\n",
      "Not found:  ENCFF015EMC\n",
      "Not found:  ENCFF197DZP\n",
      "Not found:  ENCFF693QKW\n",
      "Not found:  ENCFF342TEJ\n",
      "Not found:  ENCFF905NDM\n",
      "Not found:  ENCFF879JZU\n",
      "Not found:  ENCFF952AHW\n",
      "Not found:  ENCFF563JCI\n",
      "Not found:  ENCFF269MUV\n",
      "Not found:  ENCFF482LTF\n",
      "Not found:  ENCFF614VLQ\n",
      "Not found:  ENCFF624FHC\n",
      "Not found:  ENCFF479KNI\n",
      "Not found:  ENCFF589PEM\n",
      "Not found:  ENCFF041HBD\n",
      "Not found:  ENCFF124RDD\n",
      "Not found:  ENCFF725USM\n",
      "Not found:  ENCFF345KPY\n",
      "Not found:  ENCFF912LYR\n",
      "Not found:  ENCFF762VOE\n",
      "Not found:  ENCFF738TVC\n",
      "Not found:  ENCFF808SYD\n",
      "Not found:  ENCFF771XYK\n",
      "Not found:  ENCFF258ANV\n",
      "Not found:  ENCFF284VFV\n",
      "Not found:  ENCFF080KYI\n",
      "Not found:  ENCFF658HZK\n",
      "Not found:  ENCFF845ONN\n",
      "Not found:  ENCFF509MZI\n",
      "Not found:  ENCFF570NEW\n",
      "Not found:  ENCFF970MGQ\n",
      "Not found:  ENCFF788PUW\n",
      "Not found:  ENCFF957XRW\n",
      "Not found:  ENCFF248LJB\n",
      "Not found:  ENCFF107YAW\n",
      "Not found:  ENCFF707GIJ\n",
      "Not found:  ENCFF823FJI\n",
      "Not found:  ENCFF203FBD\n",
      "Not found:  ENCFF899VMA\n",
      "Not found:  ENCFF509ZIC\n",
      "Not found:  ENCFF009AKE\n",
      "Not found:  ENCFF354MPI\n",
      "Not found:  ENCFF586KEK\n",
      "Not found:  ENCFF166SFX\n",
      "Not found:  ENCFF367FEB\n",
      "Not found:  ENCFF042XFA\n",
      "Not found:  ENCFF457BBP\n",
      "Not found:  ENCFF311IDM\n",
      "Not found:  ENCFF180CEK\n",
      "Not found:  ENCFF822OZH\n",
      "Not found:  ENCFF258FWH\n",
      "Not found:  ENCFF015EMC\n",
      "Not found:  ENCFF197DZP\n",
      "Not found:  ENCFF693QKW\n",
      "Not found:  ENCFF342TEJ\n",
      "Not found:  ENCFF905NDM\n",
      "Not found:  ENCFF879JZU\n",
      "Not found:  ENCFF952AHW\n",
      "Not found:  ENCFF563JCI\n",
      "Not found:  ENCFF269MUV\n",
      "Not found:  ENCFF482LTF\n",
      "Not found:  ENCFF614VLQ\n",
      "Not found:  ENCFF624FHC\n",
      "Not found:  ENCFF479KNI\n",
      "Not found:  ENCFF589PEM\n",
      "Not found:  ENCFF041HBD\n",
      "Not found:  ENCFF124RDD\n",
      "Not found:  ENCFF725USM\n",
      "0\n",
      "Validation Loss: 10.169035\n",
      "1\n",
      "Validation Loss: 9.971367\n",
      "2\n",
      "Validation Loss: 10.369256\n",
      "3\n",
      "Validation Loss: 9.82305\n",
      "4\n",
      "Validation Loss: 9.971765\n",
      "5\n",
      "Validation Loss: 10.223206\n",
      "6\n",
      "Validation Loss: 9.936409\n",
      "7\n",
      "Validation Loss: 9.933583\n",
      "8\n",
      "Validation Loss: 9.964103\n",
      "9\n",
      "Validation Loss: 9.951648\n",
      "10\n",
      "Validation Loss: 10.150573\n",
      "11\n",
      "Validation Loss: 9.950607\n",
      "12\n",
      "Validation Loss: 9.897043\n",
      "13\n",
      "Validation Loss: 9.962383\n",
      "14\n",
      "Validation Loss: 9.826371\n",
      "15\n",
      "Validation Loss: 10.097372\n",
      "16\n",
      "Validation Loss: 10.23712\n",
      "17\n",
      "Validation Loss: 9.904124\n",
      "18\n",
      "Validation Loss: 10.223458\n",
      "19\n",
      "Validation Loss: 10.0213\n"
     ]
    }
   ],
   "source": [
    "batch_size=20\n",
    "num_epochs = 20\n",
    "lr=1e-4\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Set up data split\n",
    "for split in range(1):\n",
    "\n",
    "    train_ids, val_ids, test_ids = get_train_val_test(split, labels=labels)\n",
    "\n",
    "    train_ds = Rush_DNAse_Dataset(get_fnames(rush_fnames, train_ids),\n",
    "                                  label_file=labels)\n",
    "    val_ds = Rush_DNAse_Dataset(get_fnames(rush_fnames, val_ids),\n",
    "                                  label_file=labels)\n",
    "    test_ds = Rush_DNAse_Dataset(get_fnames(rush_fnames, test_ids),\n",
    "                                  label_file=labels)\n",
    "\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_ds,\n",
    "                            batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_ds,\n",
    "                            batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds,\n",
    "                            batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    best_model = train_epishift(train_dataloader=train_loader, \n",
    "                                val_dataloader=val_loader, num_epochs=num_epochs,\n",
    "                                lr=lr, pretrain_encoder=pretrain_encoder)\n",
    "    results[split] = test_epishift(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(best_model.state_dict(), 'trained_100epoch_pre_1000epoch_500data_fulldna_onlymask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7865924321056079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff22dfa2810>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Without pretraining\n",
    "# New split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(results[split]['truth'], results[split]['pred'])\n",
    "print(roc_auc_score(results[split]['truth'], results[split]['pred']))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7837006154457018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f319e11f710>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# New split (with pretrianing)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(results[split]['truth'], results[split]['pred'])\n",
    "print(roc_auc_score(results[split]['truth'], results[split]['pred']))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsnap",
   "language": "python",
   "name": "deepsnap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
